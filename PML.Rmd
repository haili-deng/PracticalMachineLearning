---
title: "Human Action Recognition"
author: "Haili DENG"
date: "August 18, 2015"
output: html_document
---

# Part I: Data Loading and Cleansing
## 0. Register multi-core processing:
In my case, it's 8-core.
```{r,message=FALSE}
require(doParallel)
registerDoParallel(cores=8)
```

## 1. Download and read raw data files:
```{r,message=FALSE}
filePath1<-paste0(getwd(),"/pml-training.csv")
filePath2<-paste0(getwd(),"/pml-testing.csv")
if (!file.exists(filePath1)){
    fileURL<-"http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
    download.file(fileURL,destfile = filePath1)
    rm(fileURL)
    }
if(!file.exists(filePath2)){
    fileURL<-"http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
    download.file(fileURL,destfile = filePath2)
    rm(fileURL)
    }
if (!exists("RawData")) RawData<-read.csv(filePath1)
if (!exists("TestData")) TestData<-read.csv(filePath2)
rm(filePath1,filePath2)
```
## 2. Data cleaning
Remove columns with NAs and bookeeping entries that have no predictive value. By inspection 
the header of RawData, we pick out and store the relevant colnames name to vector *keep*

```{r,message=FALSE}
data.cleaning<-function(x,classe=TRUE){
    keep<-c("user_name","roll_belt","pitch_belt","yaw_belt","total_accel_belt","gyros_belt_x","gyros_belt_y","gyros_belt_z","accel_belt_x","accel_belt_y","accel_belt_z","magnet_belt_x","magnet_belt_y","magnet_belt_z","roll_arm","pitch_arm","yaw_arm","total_accel_arm","gyros_arm_x","gyros_arm_y","gyros_arm_z","accel_arm_x","accel_arm_y","accel_arm_z","magnet_arm_x","magnet_arm_y","magnet_arm_z","roll_dumbbell","pitch_dumbbell","yaw_dumbbell","total_accel_dumbbell","gyros_dumbbell_x","gyros_dumbbell_y","gyros_dumbbell_z","accel_dumbbell_x","accel_dumbbell_y","accel_dumbbell_z","magnet_dumbbell_x","magnet_dumbbell_y","magnet_dumbbell_z","roll_forearm","pitch_forearm","yaw_forearm","total_accel_forearm","gyros_forearm_x","gyros_forearm_y","gyros_forearm_z","accel_forearm_x","accel_forearm_y","accel_forearm_z","magnet_forearm_x","magnet_forearm_y","magnet_forearm_z","classe")
    if (!classe) keep<-keep[1:53]
    return(x[keep])
}
CleanedData<-data.cleaning(RawData,classe=TRUE)
```

# Part II: Data exploration and model selection
## 3. Data slicing
The dataset is generated by 6 participants:**`r levels(CleanedData$user_name)`**, and they might show different features even for the same class of action. Therefore, it make sense to sub-divide the dataset into six group.
```{r,message=FALSE}
participant<-levels(CleanedData$user_name)
for (i in 1:6){
    temp<-CleanedData[CleanedData$user_name==participant[i],2:54]
    assign(participant[i],temp)   
}
rm(temp,i)
```
## 4. Exploratory Analysis
First we compared two dataset generated by adelmo and pedro(one have the most observation and another the least.)
```{r,message=FALSE}
require(caret)
featurePlot(x=adelmo[,2:52],y=adelmo$classe)
featurePlot(x=pedro[,2:52],y=pedro$classe)

```
We can Observe that the predictors are not center and scale properly.
Some predictors might have zero variability, therefore we perform a test and remove the relevant column.
```{r,message=FALSE}
nearZeroVar(adelmo)
nearZeroVar(carlitos)
nearZeroVar(charles)
nearZeroVar(eurico)
nearZeroVar(jeremy)
nearZeroVar(pedro)
```
```{r,message=FALSE}
adelmo<-adelmo[,-nearZeroVar(adelmo)]
jeremy<-jeremy[,-nearZeroVar(jeremy)]
```
## 5. Model Selection
Try out different model and assess their performance with subset pedro.
```{r,message=FALSE}
require(randomForest)
inBuild<-createDataPartition(y=pedro$classe,p=0.8,list=FALSE)
pedro_training<-pedro[inBuild,]
# Creat cross-validation subset
pedro_X_validation<-pedro[-inBuild,]
# Creat training and testing subset
inTrain_sub<-createDataPartition(y=pedro_training$classe,p=0.75,list=FALSE)
pedro_testing_sub<-pedro_training[-inTrain_sub,]
pedro_training_sub<-pedro_training[inTrain_sub,]
# Random Forest
RfFit<-randomForest(classe~.,data=pedro_training_sub,preProcess=c("center","scale"))
Rf_pred<-predict(RfFit,pedro_testing_sub)
Rf_val_pred<-predict(RfFit,pedro_X_validation)
confusionMatrix(pedro_testing_sub$classe,Rf_pred)
varImpPlot(RfFit)
# Bagging
treebag <- bag(x=pedro_training_sub[,1:52],y=pedro_training_sub$classe, B = 20,bagControl = bagControl(fit = ctreeBag$fit,predict = ctreeBag$pred,aggregate = ctreeBag$aggregate),preProcess=c("center","scale"))
treebag_pred<-predict(treebag,pedro_testing_sub)
confusionMatrix(pedro_testing_sub$classe,treebag_pred)
varImpPlot(RfFit)
# Boosting
gbmFit<-train(classe~.,method='gbm',data=pedro_training_sub,preProcess=c("center","scale"))
gbm_pred<-predict(gbmFit,pedro_testing_sub)
confusionMatrix(pedro_testing_sub$classe,gbm_pred)
plot(varImp(gbmFit, scale = FALSE),top= 30)
# Linear Discriminant Analysis
ldaFit<-train(classe~.,method='lda',data=pedro_training_sub,preProcess=c("center","scale"))
lda_pred<-predict(ldaFit,pedro_testing_sub)
confusionMatrix(pedro_testing_sub$classe,lda_pred)
```
Part III Cross validation and out of sample error
## 6. Cross validation
Repeat step 4 several 10 times with different seed, we found that random forest provided the predicting power in term of accuracy. 
## 7. Errors estimation
One of the out of sample error should be as 
```{r,message=FALSE}
confusionMatrix(pedro_X_validation$classe,Rf_val_pred)
```
Which is significantly less than the acceptable level with the 95% CI.
## 8. Applying algorithm
And we use the algorithm to 20 test cases.All 20 testing observations are correctly classified.

```{r,eval=FALSE}
get.answers<-function(x,y=TestData){
    require(randomForest)
    RfFit<-randomForest(classe~.,data=x,preProcess=c("center","scale"))
    answers<-predict(RfFit,TestData[y$user_name==deparse(substitute(x)),])
    return(answers)
}
```



